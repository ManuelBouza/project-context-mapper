# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/requirements.txt
#--------------------------------------------------------------------------------
fastapi[standard]
sqlmodel
psycopg2
alembic
python-dotenv


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/alembic.ini
#--------------------------------------------------------------------------------
# A generic, single database configuration.

[alembic]
# path to migration scripts
# Use forward slashes (/) also on windows to provide an os agnostic path
script_location = alembic

# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s
# Uncomment the line below if you want the files to be prepended with date and time
# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file
# for all available tokens
file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.
prepend_sys_path = .

# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python>=3.9 or backports.zoneinfo library.
# Any required deps can installed by adding `alembic[tz]` to the pip requirements
# string value is passed to ZoneInfo()
# leave blank for localtime
# timezone =

# max length of characters to apply to the "slug" field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to alembic/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by "version_path_separator" below.
# version_locations = %(here)s/bar:%(here)s/bat:alembic/versions

# version path separator; As mentioned above, this is the character used to split
# version_locations. The default within new alembic.ini files is "os", which uses os.pathsep.
# If this key is omitted entirely, it falls back to the legacy behavior of splitting on spaces and/or commas.
# Valid values for version_path_separator are:
#
# version_path_separator = :
# version_path_separator = ;
# version_path_separator = space
# version_path_separator = newline
version_path_separator = os  # Use os.pathsep. Default configuration used for new projects.

# set to 'true' to search source files recursively
# in each "version_locations" directory
# new in Alembic version 1.10
# recursive_version_locations = false

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

# sqlalchemy.url = driver://user:pass@localhost/dbname


[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console_scripts runner, against the "black" entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# lint with attempts to fix using "ruff" - use the exec runner, execute a binary
# hooks = ruff
# ruff.type = exec
# ruff.executable = %(here)s/.venv/bin/ruff
# ruff.options = --fix REVISION_SCRIPT_FILENAME

# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARNING
handlers = console
qualname =

[logger_sqlalchemy]
level = WARNING
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/requirements-dev.txt
#--------------------------------------------------------------------------------
-r requirements.txt
pytest
pytest-cov
ruff

# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/.env
#--------------------------------------------------------------------------------
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DEV_DB=postgres
POSTGRES_TEST_DB=test_db
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

DATABASE_URL=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}

TEST_DATABASE_URL=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_TEST_DB}


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/pyproject.toml
#--------------------------------------------------------------------------------
[tool.ruff]
line-length = 120
target-version = "py312"

# Selección de reglas: E (errores de estilo), F (errores de Pyflakes) y T (type checking)
lint.select = ["E", "F", "I", "T", "UP"]

# Ignorar reglas innecesarias (opcional)
lint.ignore = ["D203"]

# Configuración de chequeo de tipos
lint.mccabe.max-complexity = 5

lint.isort.known-first-party = ["app"]


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/.gitignore
#--------------------------------------------------------------------------------
# Ignore Python cache directories
__pycache__/
*.pyc
*.pyo

# Ignore coverage report generated by pytest-cov
.coverage


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/app/database.py
#--------------------------------------------------------------------------------
import os

from dotenv import load_dotenv
from sqlmodel import Session, create_engine

# Load environment variables
load_dotenv()

# Read DATABASE_URL directly from .env
DATABASE_URL = os.getenv("DATABASE_URL")
if not DATABASE_URL:
    raise ValueError("DATABASE_URL is not set in the .env file")

# Create the SQLModel engine
engine = create_engine(DATABASE_URL, echo=True)


# Dependency to get a database session
def get_session():
    with Session(engine) as session:
        yield session


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/app/main.py
#--------------------------------------------------------------------------------
# ./app/main.py

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from app.routers.greeting_routes import router as greeting_router

app = FastAPI()


app.add_middleware(
    CORSMiddleware,
    # Cambia según la URL del frontend
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(greeting_router)


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/app/crud/greeting.py
#--------------------------------------------------------------------------------
# ./app/crud/greeting.py

from sqlmodel import Session, select

from app.models.greeting import Greeting


def create_greeting(session: Session, greeting: Greeting) -> Greeting:
    # Add a new greeting to the database
    session.add(greeting)
    session.commit()
    session.refresh(greeting)
    return greeting


def read_all_greetings(session: Session) -> list[Greeting]:
    """
    Retrieve all greetings from the database.
    """
    return list(session.exec(select(Greeting)).all())


def read_greeting_by_id(session: Session, greeting_id: int) -> Greeting | None:
    """
    Retrieve a specific greeting by ID.
    """
    return session.get(Greeting, greeting_id)


def update_greeting(session: Session, greeting_id: int, updated_greeting: Greeting) -> Greeting | None:
    """
    Update an existing greeting by its ID.
    Returns the updated greeting if successful, otherwise None.
    """
    existing_greeting = session.get(Greeting, greeting_id)
    if not existing_greeting:
        return None
    existing_greeting.text = updated_greeting.text
    session.add(existing_greeting)
    session.commit()
    session.refresh(existing_greeting)
    return existing_greeting


def delete_greeting(session: Session, greeting_id: int) -> Greeting | None:
    """
    Delete a greeting by its ID.
    Returns the deleted greeting if successful, otherwise None.
    """
    greeting = session.get(Greeting, greeting_id)
    if not greeting:
        return None
    session.delete(greeting)
    session.commit()
    return greeting


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/app/models/greeting.py
#--------------------------------------------------------------------------------
from sqlmodel import SQLModel, Field
from typing import Optional

class Greeting(SQLModel, table=True):
    id: Optional[int] = Field(default=None, primary_key=True)
    text: str


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/app/models/__init__.py
#--------------------------------------------------------------------------------
from app.models.greeting import Greeting


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/app/routers/greeting_routes.py
#--------------------------------------------------------------------------------
# ./app/routers/greeting_routes.py

from fastapi import APIRouter, Depends, HTTPException
from sqlmodel import Session

from app.crud.greeting import (
    create_greeting,
    delete_greeting,
    read_all_greetings,
    read_greeting_by_id,
    update_greeting,
)
from app.database import get_session
from app.models.greeting import Greeting

router = APIRouter(
    prefix="/greetings",
    tags=["Greetings"],
    dependencies=[Depends(get_session)],
    responses={404: {"description": "Greeting not found"}},
)


@router.post("/", response_model=Greeting)
def create_greeting_endpoint(greeting: Greeting, session: Session = Depends(get_session)) -> Greeting:
    return create_greeting(session=session, greeting=greeting)


@router.get("/", response_model=list[Greeting])
def get_all_greetings(session: Session = Depends(get_session)) -> list[Greeting]:
    return read_all_greetings(session=session)


@router.get("/{greeting_id}", response_model=Greeting)
def get_greeting_by_id(greeting_id: int, session: Session = Depends(get_session)) -> Greeting:
    greeting = read_greeting_by_id(session=session, greeting_id=greeting_id)
    if not greeting:
        raise HTTPException(status_code=404, detail="Greeting not found")
    return greeting


@router.put("/{greeting_id}", response_model=Greeting)
def update_greeting_endpoint(
    greeting_id: int, updated_greeting: Greeting, session: Session = Depends(get_session)) -> Greeting:
    greeting = update_greeting(
        session=session, greeting_id=greeting_id, updated_greeting=updated_greeting
    )
    if not greeting:
        raise HTTPException(status_code=404, detail="Greeting not found")
    return greeting


@router.delete("/{greeting_id}", response_model=Greeting)
def delete_greeting_endpoint(
    greeting_id: int, session: Session = Depends(get_session)
) -> Greeting:
    greeting = delete_greeting(session=session, greeting_id=greeting_id)
    if not greeting:
        raise HTTPException(status_code=404, detail="Greeting not found")
    return greeting


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/alembic/env.py
#--------------------------------------------------------------------------------
import os
import sys
from logging.config import fileConfig

from dotenv import load_dotenv
from sqlalchemy import engine_from_config, pool
from sqlmodel import SQLModel

from alembic import context

# Load environment variables from .env
load_dotenv()

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# add your model's MetaData object here
# for 'autogenerate' support
target_metadata = SQLModel.metadata

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.

# Detect if pytest is running and retrieve the correct database URL
database_url: str | None = os.getenv("TEST_DATABASE_URL") if "pytest" in sys.modules else os.getenv("DATABASE_URL")


if not database_url:
    raise ValueError("DATABASE_URL is not set in the environment variables.")

config.set_main_option("sqlalchemy.url", database_url)


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """
    connectable = engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/alembic/README
#--------------------------------------------------------------------------------
Generic single-database configuration.

# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/alembic/script.py.mako
#--------------------------------------------------------------------------------
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
import sqlmodel
${imports if imports else ""}

# revision identifiers, used by Alembic.
revision: str = ${repr(up_revision)}
down_revision: Union[str, None] = ${repr(down_revision)}
branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}


def upgrade() -> None:
    ${upgrades if upgrades else "pass"}


def downgrade() -> None:
    ${downgrades if downgrades else "pass"}


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/alembic/versions/2024_12_12_1844-cd5985347f03_create_greeting_table.py
#--------------------------------------------------------------------------------
"""Create greeting table

Revision ID: cd5985347f03
Revises: 
Create Date: 2024-12-12 18:44:26.724443

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
import sqlmodel


# revision identifiers, used by Alembic.
revision: str = 'cd5985347f03'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('greeting',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('text', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('greeting')
    # ### end Alembic commands ###


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/tests/conftest.py
#--------------------------------------------------------------------------------
import os
from collections.abc import Generator

import pytest
from dotenv import load_dotenv
from fastapi.testclient import TestClient
from sqlalchemy.engine import Connection, Engine
from sqlmodel import Session, create_engine

from alembic import command
from alembic.config import Config
from app.database import get_session
from app.main import app

# Load environment variables
load_dotenv()

# Retrieve the test database URL from environment variables
TEST_DATABASE_URL: str | None = os.getenv("TEST_DATABASE_URL")
if not TEST_DATABASE_URL:
    raise ValueError(
        "TEST_DATABASE_URL is not set in the environment variables.")

# Create the test database engine
engine: Engine = create_engine(TEST_DATABASE_URL, echo=False)


@pytest.fixture(scope="session")
def setup_database() -> Generator[None, None, None]:
    """
    Applies Alembic migrations before tests and rolls them back afterward.
    """
    alembic_cfg: Config = Config("alembic.ini")
    alembic_cfg.attributes["connection"] = engine.connect()
    command.upgrade(alembic_cfg, "head")
    yield
    command.downgrade(alembic_cfg, "base")


@pytest.fixture()
def session(setup_database) -> Generator[Session, None, None]:
    """
    Provides a SQLModel database session for tests with transaction rollback.
    """
    connection: Connection = engine.connect()
    transaction = connection.begin()

    session: Session = Session(bind=connection)
    yield session

    session.close()
    transaction.rollback()
    connection.close()


@pytest.fixture
def test_client(session: Session) -> Generator[TestClient, None, None]:
    """
    Provides a FastAPI test client with a database session.
    """
    def override_get_session() -> Generator[Session, None, None]:
        yield session

    app.dependency_overrides[get_session] = override_get_session
    client: TestClient = TestClient(app)
    yield client
    app.dependency_overrides.clear()


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/tests/__init__.py
#--------------------------------------------------------------------------------


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/tests/unit/test_crud_greeting.py
#--------------------------------------------------------------------------------
# ./tests/unit/test_crud_greeting.py

from unittest.mock import MagicMock

from sqlmodel import Session

from app.crud.greeting import create_greeting, delete_greeting, read_all_greetings, read_greeting_by_id, update_greeting
from app.models.greeting import Greeting


def test_create_greeting():
    """
    Test the create_greeting function using mocks to validate database interaction.
    """
    mock_session = MagicMock(spec=Session)
    new_greeting = Greeting(text="Hello, Mock!")

    result = create_greeting(session=mock_session, greeting=new_greeting)

    mock_session.add.assert_called_once_with(new_greeting)
    mock_session.commit.assert_called_once()
    mock_session.refresh.assert_called_once_with(new_greeting)
    assert result == new_greeting


def test_read_all_greetings():
    """
    Test the read_all_greetings function.
    Verifies it returns all greetings correctly.
    """
    # Arrange
    mock_session = MagicMock(spec=Session)
    mock_greetings = [Greeting(id=1, text="Hello!"),
                      Greeting(id=2, text="Hi there!")]
    mock_session.exec.return_value.all.return_value = mock_greetings

    # Act
    result = read_all_greetings(session=mock_session)

    # Assert
    assert result == mock_greetings
    mock_session.exec.assert_called_once()


def test_read_greeting_by_id():
    """
    Test the read_greeting_by_id function.
    Verifies it returns the correct greeting by ID.
    """
    # Arrange
    mock_session = MagicMock(spec=Session)
    mock_greeting = Greeting(id=1, text="Hello!")
    mock_session.get.return_value = mock_greeting

    # Act
    result = read_greeting_by_id(session=mock_session, greeting_id=1)

    # Assert
    assert result == mock_greeting
    mock_session.get.assert_called_once_with(Greeting, 1)


def test_update_greeting():
    """
    Unit test for update_greeting function.
    Verifies that the greeting is updated correctly.
    """
    # Arrange
    mock_session = MagicMock(spec=Session)
    existing_greeting = Greeting(id=1, text="Original Greeting")
    updated_data = Greeting(text="Updated Greeting")

    # Simulate retrieving the existing greeting
    mock_session.get.return_value = existing_greeting

    # Act
    result = update_greeting(session=mock_session,
                             greeting_id=1, updated_greeting=updated_data)

    # Assert
    assert result.text == "Updated Greeting"
    mock_session.get.assert_called_once_with(Greeting, 1)
    mock_session.add.assert_called_once_with(existing_greeting)
    mock_session.commit.assert_called_once()
    mock_session.refresh.assert_called_once_with(existing_greeting)


def test_delete_greeting():
    """
    Unit test for delete_greeting function.
    Verifies that the greeting is deleted correctly.
    """
    # Arrange
    mock_session = MagicMock(spec=Session)
    existing_greeting = Greeting(id=1, text="Hello, Delete Me!")

    # Simulate retrieving the existing greeting
    mock_session.get.return_value = existing_greeting

    # Act
    result = delete_greeting(session=mock_session, greeting_id=1)

    # Assert
    assert result == existing_greeting
    mock_session.get.assert_called_once_with(Greeting, 1)
    mock_session.delete.assert_called_once_with(existing_greeting)
    mock_session.commit.assert_called_once()


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/tests/unit/__init__.py
#--------------------------------------------------------------------------------


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/tests/integration/__init__.py
#--------------------------------------------------------------------------------


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/tests/integration/test_create_greeting_endpoint.py
#--------------------------------------------------------------------------------
# ./tests/integration/test_create_greeting_endpoint.py

from fastapi.testclient import TestClient


def test_create_greeting_endpoint(test_client: TestClient):
    """
    Integration test for the /greetings/ endpoint.
    It verifies that the greeting is created and returned correctly.
    """
    # Arrange
    payload = {"text": "Hello, Integration Test!"}

    # Act
    response = test_client.post("/greetings/", json=payload)

    # Assert
    assert response.status_code == 200
    data = response.json()
    assert "id" in data
    assert data["text"] == payload["text"]


def test_get_all_greetings(test_client: TestClient):
    """
    Integration test for the GET /greetings/ endpoint.
    Verifies it returns all greetings in the database.
    """
    # Arrange: Inserta saludos en la base de datos
    test_client.post("/greetings/", json={"text": "Hello!"})
    test_client.post("/greetings/", json={"text": "Hi there!"})

    # Act: Realiza la petición al endpoint
    response = test_client.get("/greetings/")

    # Assert: Verifica la respuesta
    assert response.status_code == 200
    data = response.json()
    assert isinstance(data, list)
    assert len(data) == 2
    assert data[0]["text"] == "Hello!"
    assert data[1]["text"] == "Hi there!"


def test_get_greeting_by_id(test_client: TestClient):
    """
    Integration test for the GET /greetings/{greeting_id} endpoint.
    Verifies it retrieves the correct greeting by ID.
    """
    # Arrange: Inserta un saludo en la base de datos
    response_post = test_client.post(
        "/greetings/", json={"text": "Hello, ID Test!"})
    greeting_id = response_post.json()["id"]

    # Act: Recupera el saludo por su ID
    response_get = test_client.get(f"/greetings/{greeting_id}")

    # Assert: Verifica la respuesta
    assert response_get.status_code == 200
    data = response_get.json()
    assert data["id"] == greeting_id
    assert data["text"] == "Hello, ID Test!"


def test_get_greeting_by_id_not_found(test_client: TestClient):
    """
    Integration test for the GET /greetings/{greeting_id} endpoint.
    Verifies it returns 404 when the greeting is not found.
    """
    # Act: Intenta recuperar un saludo con un ID inexistente
    response = test_client.get("/greetings/9999")

    # Assert: Verifica que devuelve un error 404
    assert response.status_code == 404
    assert response.json() == {"detail": "Greeting not found"}


def test_update_greeting(test_client: TestClient):
    """
    Integration test for PUT /greetings/{greeting_id}.
    Verifies that a greeting is updated correctly.
    """
    # Arrange: Insert an initial greeting into the database
    response_post = test_client.post(
        "/greetings/", json={"text": "Initial Greeting"})
    greeting_id = response_post.json()["id"]

    # Act: Update the greeting using the PUT endpoint
    response_put = test_client.put(
        f"/greetings/{greeting_id}", json={"text": "Updated Greeting"})

    # Assert: Verify the response contains the updated data
    assert response_put.status_code == 200
    data = response_put.json()
    assert data["id"] == greeting_id
    assert data["text"] == "Updated Greeting"


def test_update_greeting_not_found(test_client: TestClient):
    """
    Integration test for PUT /greetings/{greeting_id} when the greeting does not exist.
    Verifies that the endpoint returns a 404 status code.
    """
    # Act: Attempt to update a non-existent greeting
    response_put = test_client.put(
        "/greetings/9999", json={"text": "Nonexistent Greeting"})

    # Assert: Verify the response returns a 404 status code
    assert response_put.status_code == 404
    assert response_put.json() == {"detail": "Greeting not found"}


def test_delete_greeting(test_client: TestClient):
    """
    Integration test for DELETE /greetings/{greeting_id}.
    Verifies that a greeting is deleted correctly.
    """
    # Arrange: Insert a greeting into the database
    response_post = test_client.post(
        "/greetings/", json={"text": "Greeting to Delete"})
    greeting_id = response_post.json()["id"]

    # Act: Delete the greeting using the DELETE endpoint
    response_delete = test_client.delete(f"/greetings/{greeting_id}")

    # Assert: Verify the response contains the deleted greeting
    assert response_delete.status_code == 200
    data = response_delete.json()
    assert data["id"] == greeting_id
    assert data["text"] == "Greeting to Delete"

    # Verify the greeting no longer exists
    response_get = test_client.get(f"/greetings/{greeting_id}")
    assert response_get.status_code == 404


def test_delete_greeting_not_found(test_client: TestClient):
    """
    Integration test for DELETE /greetings/{greeting_id} when the greeting does not exist.
    Verifies that the endpoint returns a 404 status code.
    """
    # Act: Attempt to delete a non-existent greeting
    response_delete = test_client.delete("/greetings/9999")

    # Assert: Verify the response returns a 404 status code
    assert response_delete.status_code == 404
    assert response_delete.json() == {"detail": "Greeting not found"}


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/.devcontainer/docker-compose.yml
#--------------------------------------------------------------------------------
version: '3.8'

services:
  api:
    build:
      context: ..
      dockerfile: .devcontainer/Dockerfile

    volumes:
      - ../..:/workspaces:cached

    # Overrides default command so things don't shut down after the process ends.
    command: sleep infinity

    # Runs app on the same network as the database container, allows "forwardPorts" in devcontainer.json function.
    network_mode: service:db

    # Use "forwardPorts" in **devcontainer.json** to forward an app port locally.
    # (Adding the "ports" property to this file will not forward from a Codespace.)

  db:
    image: postgres:16-bullseye
    
    
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d

    
    environment:
      POSTGRES_USER: postgres
      POSTGRES_DB: postgres
      POSTGRES_PASSWORD: postgres

    # Add "forwardPorts": ["5432"] to **devcontainer.json** to forward PostgreSQL locally.
    # (Adding the "ports" property to this file will not forward from a Codespace.)

volumes:
  postgres-data:


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/.devcontainer/devcontainer.json
#--------------------------------------------------------------------------------
// For format details, see https://aka.ms/devcontainer.json. For config options, see the
// README at: https://github.com/devcontainers/templates/tree/main/src/postgres
{
	"name": "Python 3 & PostgreSQL",
	"dockerComposeFile": "docker-compose.yml",
	"service": "api",
	"workspaceFolder": "/workspaces/${localWorkspaceFolderBasename}",

	// Features to add to the dev container. More info: https://containers.dev/features.
	// "features": {},

    // Use 'forwardPorts' to make a list of ports inside the container available locally.
    "forwardPorts": [8000, 5432],

    "portsAttributes": {
		"8000": {"label": "FastAPI port", "onAutoForward": "notify"},
		"5432": {"label": "PostgreSQL port", "onAutoForward": "silent"}
    },

	// Use 'postCreateCommand' to run commands after the container is created.
	"postCreateCommand": "pip3 install --user -r requirements-dev.txt",

	// Configure tool-specific properties.
	"customizations": {
		"vscode": {
			"extensions": [
				"ms-python.mypy-type-checker",
				"ms-azuretools.vscode-docker",
				"mtxr.sqltools",
				"mtxr.sqltools-driver-pg",
				"charliermarsh.ruff"
			]
		}
	}

	// Uncomment to connect as root instead. More info: https://aka.ms/dev-containers-non-root.
	// "remoteUser": "root"
}


# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/.devcontainer/Dockerfile
#--------------------------------------------------------------------------------
FROM mcr.microsoft.com/devcontainers/python:1-3.12-bullseye

ENV PYTHONUNBUFFERED 1

# [Optional] If your requirements rarely change, uncomment this section to add them to the image.
# COPY requirements.txt /tmp/pip-tmp/
# RUN pip3 --disable-pip-version-check --no-cache-dir install -r /tmp/pip-tmp/requirements.txt \
#    && rm -rf /tmp/pip-tmp

# [Optional] Uncomment this section to install additional OS packages.
# RUN apt-get update && export DEBIAN_FRONTEND=noninteractive \
#     && apt-get -y install --no-install-recommends <your-package-list-here>





# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/.devcontainer/init-scripts/01_create_test_db.sql
#--------------------------------------------------------------------------------
CREATE DATABASE test_db;
    

# Ruta: /home/manuel/Work/project-name_full-stack/project-name_backend/.github/dependabot.yml
#--------------------------------------------------------------------------------
# To get started with Dependabot version updates, you'll need to specify which
# package ecosystems to update and where the package manifests are located.
# Please see the documentation for more information:
# https://docs.github.com/github/administering-a-repository/configuration-options-for-dependency-updates
# https://containers.dev/guide/dependabot

version: 2
updates:
 - package-ecosystem: "devcontainers"
   directory: "/"
   schedule:
     interval: weekly


